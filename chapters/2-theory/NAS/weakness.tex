\subsection{Challenges}
\subsubsection{Computational power}
The most straightforward approach to determine the performance of a neural network is to train it until the validation accuracy has converged against a value or has been run for a fixed amount of epochs. However, training thousands of architectures may require hundreds or more \gls{GPU} days \autocite{ren2021comprehensive}. The computational power required may be available for larger companies with plentiful resources. However, for most users, this is computationally infeasible. As a result, the necessary computational power is considered a significant challenge for \gls{NAS}. 

\subsubsection{Black-box optimisation and lack of interpretability}
\gls{NAS} algorithms often treat the architecture search space as a black box, meaning they cannot access the internal workings of the searched model architectures. This can make it difficult to incorporate domain knowledge or bias the search towards certain types of architectures. This results in difficult-to-interpret architectures, making it challenging to understand how they make predictions or identify potential problems with the architecture. \autocite{https://doi.org/10.48550/arxiv.1806.09055}
