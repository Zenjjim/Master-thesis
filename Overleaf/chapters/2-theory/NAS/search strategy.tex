\subsection{Search Strategies}

\subsubsection{Random Search}
Random search is the most naive search strategy, and it will simply randomly pick a good architecture based on the search space. Therefore, the method is relatively fast and does not require any learning model. A random search may be effective if a search space is well constructed.  

\subsubsection{Reinforcement Learning}
On the very basic, reinforcement learning is an area within machine learning in which an agent learns behaviour by some trial-and-error interaction with a dynamic environment \autocite{kaelbling1996reinforcement}. One can consider \gls{NAS} a reinforcement problem by looking at the creation of the architecture as the agent's action, in which the action space is the problem's search space. The agent gets rewarded depending on the performance of the trained architecture. There are numerous approaches to representing an agent's policy, such as a recurrent neural network, proximal policy optimisation and q-learning \autocite{elsken2019neural}. 

\subsubsection{Evolutionary algorithms}
\glsreset{EC}
Evolutionary algorithms are techniques used in optimisation and search methods. It is a subset of \gls{EC} and is an effective way of problem-solving for often encountered global optimisation problems \autocite{7955308}. Evolutionary algorithms in \gls{NAS} randomly select $N$ initialised models and then evaluate performance by the given evaluation strategy. The best models are chosen as parents, and new models have mutated clones of the parents, which are re-evaluated. Finally, the worst $N$ models are removed from the population to make room for new children \autocite{https://doi.org/10.48550/arxiv.1703.01041}. 

\subsubsection{Bayesian optimisation}
\glsreset{BO}
\Gls{BO} has been a popular approach for hyperparameter optimisation \autocite{elsken2019neural}. In general, \gls{BO} optimises expensive functions to evaluate, such as the performance of architectures. This is a global optimisation problem that \gls{BO} tries to solve. Given a costly to evaluate function $f$, \gls{BO} aims at finding its optimal score within some domain $x$ \autocite{kandasamy2018neural}. In other words, \gls{BO} pursues to calculate $a^* = \text{arg min}_{a \in A} f(a)$, where $A$ is the given search space, and $f(a)$ is the performance function of the neural network after training the architecture $a$ for a fixed number of iterations \autocite{white2021bananas}.  
